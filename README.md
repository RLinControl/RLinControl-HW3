# Homework 3

## üìù Homework Description

This repository contains the implementation for Homework 3 of the Reinforcement Learning in Control course. The assignment focuses on implementing and analyzing fundamental reinforcement learning algorithms for solving Markov Decision Processes (MDPs).

### Components

#### Part 1: Rover Bot MDP
- Implementation of the **Value Iteration (VI)** algorithm
- Application to a custom Rover Bot MDP problem as described in the homework PDF
- Analysis of convergence and optimal policy computation

#### Part 2: MiniGrid Environment
- Installation and setup of the MiniGrid environment
- Exploration of MiniGrid's features and capabilities
- Implementation of both **Value Iteration (VI)** and **Policy Iteration (PI)** algorithms
- Performance comparison and analysis on selected MiniGrid environments


## üîß Implementation Details

### Value Iteration (VI)
- Iterative algorithm for computing optimal value functions
- Convergence criteria based on Bellman error
- Optimal policy extraction from converged value function

### Policy Iteration (PI)
- Policy evaluation and policy improvement steps
- Guaranteed convergence to optimal policy
- Comparison with VI in terms of iterations and computation time

## ü§ù Contributing

This is an academic assignment. Please ensure you follow your institution's academic integrity policies.


## üìß Contact

For questions about this implementation, please contact through the course group or create an issue in this repository.
